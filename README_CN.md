# aiXcoder-7B Code Large Language Model

<p align="center">
    ğŸ  <a href="https://www.aixcoder.com/" target="_blank">å®˜ç½‘</a>ï½œğŸ›  <a href="https://marketplace.visualstudio.com/items?itemName=aixcoder-plugin.aixcoder" target="_blank">VS Code æ’ä»¶</a>ï½œğŸ›  <a href="https://plugins.jetbrains.com/plugin/13574-aixcoder-code-completer" target="_blank">Jetbrains æ’ä»¶</a>ï½œğŸ¤— <a href="https://huggingface.co/aiXcoder/aixcoder-7b-base" target="_blank">æ¨¡å‹ä¸‹è½½</a>ï½œ<a href="./assets/wechat_1.jpg" target="_blank">æŠ€æœ¯äº¤æµç¾¤</a>ï½œ<a href="./assets/wechat_2.jpg" target="_blank">å…¬ä¼—å·</a>
</p>

æ¬¢è¿æ¥åˆ°aiXcoder-7Bä»£ç å¤§å‹è¯­è¨€æ¨¡å‹çš„å®˜æ–¹ä»“åº“ã€‚è¯¥æ¨¡å‹æ—¨åœ¨ç†è§£å’Œç”Ÿæˆå¤šç§ç¼–ç¨‹è¯­è¨€ä¸­çš„ä»£ç ï¼Œæä¾›åœ¨ä»£ç å®Œæˆã€ç†è§£ã€ç”Ÿæˆä»¥åŠæ›´å¤šå…³äºç¼–ç¨‹è¯­è¨€çš„ä»»åŠ¡ä¸­çš„æœ€å…ˆè¿›æ€§èƒ½ã€‚

ç›®å½•

1. [æ¨¡å‹ç®€ä»‹](#æ¨¡å‹ç®€ä»‹)
2. [å¿«é€Ÿä¸Šæ‰‹](#å¿«é€Ÿä¸Šæ‰‹)
    - [è¿è¡Œç¯å¢ƒ](#è¿è¡Œç¯å¢ƒ)
    - [æ¨¡å‹æƒé‡](#æ¨¡å‹æƒé‡)
    - [æ¨ç†ç¤ºä¾‹](#æ¨ç†ç¤ºä¾‹)
3. [aiXcoder 7B è®­ç»ƒæ•°æ®](#aixcoder-7b-è®­ç»ƒæ•°æ®)
4. [è®­ç»ƒ](#è®­ç»ƒ)
    - [è®­ç»ƒè¶…å‚æ•°](#è®­ç»ƒè¶…å‚æ•°)
    <!-- - [æ‰¹é‡æ•°æ®ç»„ç»‡æ–¹å¼](#æ‰¹é‡æ•°æ®ç»„ç»‡æ–¹å¼)
    - [é¢„è®­ç»ƒä»»åŠ¡](#é¢„è®­ç»ƒä»»åŠ¡) -->
5. [å®éªŒç»“æœ](#å®éªŒç»“æœ)
    - [NL2Code åŸºå‡†æµ‹è¯•](#nl2code-åŸºå‡†æµ‹è¯•)
    - [ä»£ç è¡¥å…¨ (Fill in the Middle)](#ä»£ç è¡¥å…¨-fill-in-the-middle)
    - [è·¨æ–‡ä»¶ä»£ç ç”Ÿæˆ](#è·¨æ–‡ä»¶ä»£ç ç”Ÿæˆ)
6. [License](#license)
7. [Acknowledgments](#acknowledgments)



## æ¨¡å‹ç®€ä»‹

éšç€ä»£ç å¤§æ¨¡å‹çš„èƒ½åŠ›é€æ¸è¢«æŒ–æ˜å‡ºæ¥ï¼ŒaiXcoder ä¹Ÿä¸€ç›´åœ¨æ€è€ƒæ€æ ·æ‰èƒ½ä»¤ä»£ç å¤§æ¨¡å‹åœ¨å®é™…å¼€å‘åœºæ™¯ä¸­æœ‰æ›´å¤§çš„å¸®åŠ©ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼€æºäº† aiXcoder 7B Baseï¼Œè¯¥æ¨¡å‹åœ¨1.2T Unique Tokensä¸Šåšäº†å¤§é‡çš„è®­ç»ƒï¼Œå¹¶ä¸”è¯¥æ¨¡å‹çš„é¢„è®­ç»ƒä»»åŠ¡åŠä¸Šä¸‹æ–‡ä¿¡æ¯éƒ½ä¸ºçœŸå®ä»£ç ç”Ÿæˆåœºæ™¯åšäº†ç‹¬ç‰¹çš„è®¾è®¡ã€‚ 

aiXcoder 7B Base åœ¨ä»£ç è¡¥å…¨åœºæ™¯ä¸‹æ˜¯æ‰€æœ‰åŒç­‰çº§å‚æ•°é‡æ¨¡å‹ä¸­æ•ˆæœæœ€å¥½çš„ï¼Œä¸»æµå¤šè¯­è¨€nl2code benchmark å¹³å‡ä¸Šæ•ˆæœä¹Ÿè¶…è¿‡codellama 34B å’ŒStarCoder2 15Bã€‚

åœ¨æˆ‘ä»¬æŒç»­æ¨åŠ¨ä»£ç å¤§æ¨¡å‹åº”ç”¨çš„æ¢ç´¢è¿‡ç¨‹ä¸­ï¼ŒaiXcoder 7B Base æ¨¡å‹çš„å‘å¸ƒæ ‡å¿—ç€ä¸€ä¸ªé‡è¦çš„é‡Œç¨‹ç¢‘ã€‚å½“å‰ç‰ˆæœ¬çš„ aiXcoder 7B Base æ˜¯ä¸€ä¸ªåŸºç¡€æ¨¡å‹ï¼Œä¸“æ³¨äºæå‡ä»£ç è¡¥å…¨å’Œä»£ç ç”Ÿæˆçš„æ•ˆç‡ä¸å‡†ç¡®æ€§ï¼Œæ—¨åœ¨ä¸ºå¼€å‘äººå‘˜åœ¨è¿™äº›åœºæ™¯ä¸‹æä¾›å¼ºæœ‰åŠ›çš„æ”¯æŒã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œè¿™ä¸ªç‰ˆæœ¬å°šæœªç»è¿‡ç‰¹åˆ«çš„instructå¾®è°ƒï¼Œæ„å‘³ç€å®ƒåœ¨ç‰¹å®šçš„é«˜çº§ä»»åŠ¡å¦‚æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå’Œä»£ç è°ƒè¯•æ–¹é¢å¯èƒ½è¿˜æœªè¾¾åˆ°æœ€ä¼˜è¡¨ç°ã€‚

ç„¶è€Œï¼Œæˆ‘ä»¬å·²ç»åœ¨è§„åˆ’ä¸­åŒ…å«äº†å¯¹aiXcoderæ¨¡å‹ç³»åˆ—çš„è¿›ä¸€æ­¥å‘å±•ã€‚åœ¨ä¸ä¹…çš„å°†æ¥ï¼Œæˆ‘ä»¬è®¡åˆ’å‘å¸ƒæ–°çš„æ¨¡å‹ç‰ˆæœ¬ï¼Œè¿™äº›ç‰ˆæœ¬å°†ç»è¿‡ç²¾å¿ƒçš„Instructå¾®è°ƒï¼Œä¸“é—¨é’ˆå¯¹æ›´å¹¿æ³›çš„ç¼–ç¨‹ä»»åŠ¡ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºæµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå’Œä»£ç è°ƒè¯•ã€‚é€šè¿‡è¿™äº›ç»è¿‡Instructå¾®è°ƒçš„æ¨¡å‹ï¼Œæˆ‘ä»¬æœŸå¾…èƒ½å¤Ÿä¸ºå¼€å‘è€…æä¾›æ›´å…¨é¢ã€æ›´æ·±å…¥çš„ç¼–ç¨‹æ”¯æŒï¼Œå¸®åŠ©ä»–ä»¬åœ¨è½¯ä»¶å¼€å‘çš„æ¯ä¸€ä¸ªé˜¶æ®µéƒ½èƒ½å‘æŒ¥å‡ºæœ€å¤§çš„æ•ˆç‡ã€‚

![table_1](./assets/table_1.png)
> aiXcoder 7B surpasses mainstream models in nl2code benchmark. aiXcoder-7B is an enhancement of aiXcoder-7B-Base, fine-tuned on one hundred thousand data entries similar to Evol-instruct for one epoch.

<br>
<br>

![table_3](./assets/table_3.png)
> aiXcoder 7B Base surpasses mainstream models in code completion scenarios. 

<br>
<br>

## å¿«é€Ÿä¸Šæ‰‹

### è¿è¡Œç¯å¢ƒ

#### é€‰æ‹©ä¸€ï¼šæ„å»ºä¸€ä¸ªè¿è¡Œç¯å¢ƒ

ä¸»è¦çš„ç¯å¢ƒä¾èµ–ä¸ºï¼š

- Python 3.8 or higher
- PyTorch 2.1.0 or higher
- sentencepiece 0.2.0 or higher
- transformers 4.34.1 or higher (if run inference by transformers library)

åœ¨æ”¯æŒCUDAç¯å¢ƒçš„å®¿ä¸»æœºæˆ–è€…å®¹å™¨å†…ï¼Œæ‰§è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…ç¯å¢ƒä¾èµ–é¡¹ï¼š

```bash
conda create -n aixcoder-7b python=3.11
conda activate aixcoder-7b
git clone git@github.com:aixcoder-plugin/aiXcoder-7b.git
cd aiXcoder-7b
pip install -r requirements.txt
```

`requirements.txt` åˆ—ä¸¾äº†æ‰€æœ‰çš„ä¾èµ–é¡¹åŠå…¶ç‰ˆæœ¬å·ã€‚

å¦‚æœæƒ³è¦åŠ å¿«æ¨ç†é€Ÿåº¦ï¼Œæˆ‘ä»¬å¼ºçƒˆå»ºè®®å®‰è£… FlashAttention åº“ï¼ˆå¯é€‰ï¼‰ã€‚åœ¨ç¡®å®šæ‚¨çš„èŠ¯ç‰‡ç‰ˆæœ¬ä¸CUDAç‰ˆæœ¬æ”¯æŒFlashAttention çš„æ¡ä»¶ä¸‹ï¼Œå¯é€šè¿‡ä»¥ä¸‹æ­¥éª¤è¿›è¡Œå®‰è£…ï¼š

```bash
git clone git@github.com:Dao-AILab/flash-attention.git
cd flash-attention
MAX_JOBS=8 python setup.py install
```

#### Option 2: Docker

ä¸ºäº†æ›´å¥½åœ°éš”ç¦»å¼€å‘ç¯å¢ƒï¼Œæˆ‘ä»¬å»ºè®®æ‚¨å¯ä»¥åœ¨ Docker å®¹å™¨å†…è¿è¡Œæ¨¡å‹æ¨ç†ã€‚å¦‚ä¸‹æ˜¯å¯åŠ¨å‡†å¤‡ docker ç¯å¢ƒçš„æ­¥éª¤ï¼š

1. å®‰è£… Dockerï¼šå¦‚æœæ‚¨çš„æœºå™¨è¿˜æ²¡æœ‰å®‰è£…Dockerï¼Œæ‚¨å¯ä»¥å‚è€ƒå®˜æ–¹çš„å®‰è£…æ­¥éª¤å®‰è£…ã€‚

2. æ‹‰å–é•œåƒ: ä» Docker Hub æ‹‰å– PyTorch é•œåƒã€‚

```bash
docker pull pytorch/pytorch:2.1.0-cuda11.8-cudnn8-devel
```

3. å¯åŠ¨å®¹å™¨: æ‹‰å–docker é•œåƒåï¼Œå¯ä»¥å¯åŠ¨å®¹å™¨ï¼Œå¹¶åœ¨å®¹å™¨ä¸­è¿è¡Œæ¨¡å‹ã€‚

```bash
docker run --gpus all -it -v /dev/shm:/dev/shm --name aix_instance pytorch/pytorch:2.1.0-cuda11.8-cudnn8-devel /bin/bash
pip install sentencepiece
git clone git@github.com:aixcoder-plugin/aiXcoder-7b.git
cd aiXcoder-7b
```

å¦‚æœæƒ³è¦åŠ å¿«æ¨ç†é€Ÿåº¦ï¼Œæˆ‘ä»¬å¼ºçƒˆå»ºè®®å®‰è£… FlashAttention åº“ï¼ˆå¯é€‰ï¼‰ã€‚åœ¨ç¡®å®šæ‚¨çš„èŠ¯ç‰‡ç‰ˆæœ¬ä¸CUDAç‰ˆæœ¬æ”¯æŒFlashAttention çš„æ¡ä»¶ä¸‹ï¼Œå¯é€šè¿‡ä»¥ä¸‹æ­¥éª¤è¿›è¡Œå®‰è£…ï¼š

```bash
git clone git@github.com:Dao-AILab/flash-attention.git
cd flash-attention
MAX_JOBS=8 python setup.py install
```

4. æ¨¡å‹æ¨ç†: åœ¨å®¹å™¨å†…ï¼Œæ‚¨å¯ä»¥å®‰è£…æ¨ç†ç¤ºä¾‹ä»£ç è¿›è¡Œé¢„æµ‹ã€‚


### æ¨¡å‹æƒé‡

æ‚¨èƒ½ä»ä»¥ä¸‹åœ°å€ä¸‹è½½æ¨¡å‹ï¼š

- [aiXcoder Base Download](https://huggingface.co/aiXcoder/aixcoder-7b-base)
- aiXcoder Instruct Download (Comming soon...)

### æ¨ç†ç¤ºä¾‹

#### å‘½ä»¤è¡Œæ‰§è¡Œ

å¦‚æœéœ€è¦å¿«é€Ÿæ‰§è¡Œï¼Œåªéœ€è¦é€šè¿‡ä»¥ä¸‹å‘½ä»¤è¡Œå³å¯è¿è¡Œæ¨ç†æ ·æœ¬:

```bash
torchrun --nproc_per_node 1 sess_megatron.py --model-dir "path/to/model_weights_dir"
```

å°† "path/to/model_weights_dir" æ›¿æ¢ä¸ºæ‚¨ä¸‹è½½æ¨¡å‹æƒé‡åçš„æœ¬åœ°åœ°å€ã€‚

æˆ–è€…é€šè¿‡ huggingface çš„ transformers åº“è¿›è¡Œæ¨ç†æµ‹è¯•ï¼š

```bash
python sess_huggingface.py
```

#### Python è„šæœ¬

å¦‚æœæ‚¨æƒ³åµŒå…¥è‡ªå·±çš„å·¥å…·æµï¼Œæˆ–è€…è·å¾—æ›´çµæ´»çš„ä½¿ç”¨æ–¹å¼ï¼Œæ‚¨èƒ½é€šè¿‡ä»¥ä¸‹ä»£ç ç›´æ¥è°ƒç”¨ï¼š

```python

from sess_megatron import TestInference

infer = TestInference()
res = infer.run_infer(
    # for FIM style input, code_string stands for prefix context
    code_string="""# å¿«é€Ÿæ’åºç®—æ³•""", 
    # for FIM style input, later_code stands for suffix context
    later_code="\n",
    # file_path should be a path from project to file
    file_path="test.py",
    # max num for generated tokens
    max_new_tokens=256,
)
print(res)

"""output:

def quick_sort(arr):
    if len(arr) <= 1:
        return arr
    pivot = arr[0]
    less = [i for i in arr[1:] if i <= pivot]
    greater = [i for i in arr[1:] if i > pivot]
    return quick_sort(less) + [pivot] + quick_sort(greater)


# æµ‹è¯•
arr = [3, 2, 1, 4, 5]
print(quick_sort(arr))  # [1, 2, 3, 4, 5]
"""

```


```python

import torch
import sys
from hf_mini.utils import input_wrapper
from transformers import AutoModelForCausalLM, AutoTokenizer

device = "cuda" # the device to load the model onto

tokenizer = AutoTokenizer.from_pretrained("aiXcoder/aixcoder-7b-base")
model = AutoModelForCausalLM.from_pretrained("aiXcoder/aixcoder-7b-base", torch_dtype=torch.bfloat16)


text = input_wrapper(
    # for FIM style input, code_string stands for prefix context
    code_string="# å¿«é€Ÿæ’åºç®—æ³•",
    # for FIM style input, later_code stands for suffix context
    later_code="\n# æµ‹è¯•\narr = [3, 2, 1, 4, 5]\nprint(quick_sort(arr))  # [1, 2, 3, 4, 5]",
    # file_path should be a path from project to file
    path="test.py"
)

if len(text) == 0:
    sys.exit()

inputs = tokenizer(text, return_tensors="pt", return_token_type_ids=False)

inputs = inputs.to(device)
model.to(device)

outputs = model.generate(**inputs, max_new_tokens=256)
print(tokenizer.decode(outputs[0], skip_special_tokens=False))



"""output:
def quick_sort(arr):
    # å¦‚æœæ•°ç»„é•¿åº¦å°äºç­‰äº1ï¼Œç›´æ¥è¿”å›
    if len(arr) <= 1:
        return arr
    # é€‰æ‹©æ•°ç»„çš„ç¬¬ä¸€ä¸ªå…ƒç´ ä½œä¸ºåŸºå‡†
    pivot = arr[0]
    # åˆå§‹åŒ–å·¦å³æŒ‡é’ˆ
    left, right = 1, len(arr) - 1
    # å¾ªç¯ç›´åˆ°å·¦æŒ‡é’ˆå°äºå³æŒ‡é’ˆ
    while left < right:
        # ä»å³åˆ°å·¦æ‰¾åˆ°ç¬¬ä¸€ä¸ªå°äºåŸºå‡†çš„å…ƒç´ ï¼Œä¸å·¦æŒ‡é’ˆå…ƒç´ äº¤æ¢
        if arr[right] < pivot:
            arr[left], arr[right] = arr[right], arr[left]
            left += 1
        # ä»å·¦åˆ°å³æ‰¾åˆ°ç¬¬ä¸€ä¸ªå¤§äºç­‰äºåŸºå‡†çš„å…ƒç´ ï¼Œä¸å³æŒ‡é’ˆå…ƒç´ äº¤æ¢
        if arr[left] >= pivot:
            right -= 1
    # å°†åŸºå‡†å…ƒç´ ä¸å·¦æŒ‡é’ˆå…ƒç´ äº¤æ¢
    arr[left], arr[0] = arr[0], arr[left]
    # å¯¹å·¦åŠéƒ¨åˆ†è¿›è¡Œé€’å½’æ’åº
    quick_sort(arr[:left])
    # å¯¹å³åŠéƒ¨åˆ†è¿›è¡Œé€’å½’æ’åº
    quick_sort(arr[left + 1:])
    return arr</s>
"""

```

## aiXcoder 7B è®­ç»ƒæ•°æ®

aiXcoder çš„æ•°æ®åˆ†ä¸ºæ ¸å¿ƒæ•°æ®é›†ä¸æ‰©å±•æ•°æ®é›†ï¼Œæ ¸å¿ƒæ•°æ®é›†ç”±ä¸šåŠ¡ä¸Šå¸¸ç”¨çš„å‡ å¤§ç¼–ç¨‹è¯­è¨€ï¼Œä»¥åŠä¸ä»£ç æ¯æ¯ç›¸å…³çš„è‡ªç„¶è¯­è¨€ç»„æˆã€‚æ ¸å¿ƒæ•°æ®é›†çš„ç¼–ç¨‹è¯­è¨€ä¸»è¦æœ‰ C++ã€Pythonã€Javaã€JavaScriptç­‰è¿‘ç™¾ç§ä¸»æµç¼–ç¨‹è¯­è¨€ï¼Œè‡ªç„¶è¯­è¨€ä¸Šä¸»è¦ç”± StackOverFlow é—®ç­”ã€æŠ€æœ¯åšå®¢ã€ä»£ç æ–‡æ¡£ã€è®¡ç®—æœºé¢†åŸŸè®ºæ–‡ç­‰ç»„æˆã€‚æ‰©å±•æ•°æ®é›†ä¸»è¦ç”±è¿‡æ»¤åçš„ä»£ç å¼€æºæ•°æ®é›†ï¼Œè‹±æ–‡è‡ªç„¶è¯­è¨€é«˜è´¨é‡æ•°æ®é›†ï¼Œä¸­æ–‡è‡ªç„¶è¯­è¨€é«˜è´¨é‡æ•°æ®é›†ç»„æˆã€‚

<!-- <br>
<br>

![table_0](./assets/table_0.png)

<br>
<br> -->


aiXcoder æ ¸å¿ƒæ•°æ®é›†ä¸»è¦ç”¨äºå¼ºåŒ–ä»£ç å¤§æ¨¡å‹åœ¨ä»¥ä¸Šç¼–ç¨‹è¯­è¨€ä¸Šçš„æ•ˆæœï¼Œå…¶ç»è¿‡å¤§é‡çš„è¿‡æ»¤ä¸ç­›é€‰è¿‡ç¨‹ã€‚å…·ä½“è€Œè¨€ä¸»è¦åˆ†ä¸ºå¦‚ä¸‹å‡ æ­¥ï¼š1) åŸå§‹æ•°æ®æŒ‘é€‰ï¼› 2) å¯¹é¡¹ç›®è¿›è¡Œç»¼åˆæ’åºï¼Œå¹¶ç­›é€‰ï¼›3) åŸºäº MinHashes(Broder, 2000) ç­‰æ–¹æ³•è¿›è¡Œä»£ç å»é‡ã€å»é™¤è‡ªåŠ¨ç”Ÿæˆçš„ä»£ç ï¼›4) ä¸ªäººæ•æ„Ÿä¿¡æ¯è¯†åˆ«ä¸å¤„ç†ï¼›5) æ¸…ç†è¢«æ³¨é‡Šçš„ä»£ç ï¼›6) è¯­æ³•åˆ†æè¿‡æ»¤ä¸æ­£ç¡®æˆ–è€…å¼‚å¸¸çš„ä»£ç æ–‡ä»¶ï¼›7ï¼‰ç»“åˆé™æ€åˆ†æå·¥å…·ï¼Œæ£€æµ‹å¹¶æ’é™¤ Java\CPP\Python\JS ç­‰ä¸»æµç¼–ç¨‹è¯­è¨€ä¸­é«˜é£é™©çš„163 ç§ bug å’Œ197 ç§ç¼ºé™·ã€‚

1. åŸå§‹æ•°æ®æŒ‘é€‰
    - æ’é™¤ copyleft licenses é¡¹ç›®
    - å¯¹ aiXcoder åœ¨å„å¤§ä»£ç æ‰˜ç®¡å¹³å°ä¸ŠæŠ“å–çš„æ•°æ®åŠå¼€æºæ•°æ®åšé¡¹ç›®å»é‡
2. é¡¹ç›®çº§çš„ç»¼åˆæ’åº
    - ç»Ÿè®¡é¡¹ç›®çš„Staré‡ã€Git Commit æ•°é‡ã€Testæ–‡ä»¶æ•°é‡ï¼Œå¹¶ç»¼åˆè¯„åˆ†
    - æ’é™¤ç»¼åˆè¯„åˆ†æœ€ä½çš„10%æ•°æ®
3. ä»£ç æ–‡ä»¶çº§ç­›é€‰
    - åˆ é™¤è‡ªåŠ¨ç”Ÿæˆä»£ç 
    - near-deduplicationå»é‡
4. æ•æ„Ÿä¿¡æ¯å»é™¤
    - å‘½åå®ä½“æ¨¡å‹è¯†åˆ«å¹¶åˆ é™¤äººåã€IPã€è´¦å·å¯†ç ã€ç½‘å€ç­‰æ•æ„Ÿä¿¡æ¯
5. è¢«æ³¨é‡Šçš„ä»£ç 
    - æŒ‰æ¯”ä¾‹éšæœºåˆ é™¤è¢«æ³¨é‡Šçš„å¤§æ®µä»£ç 
6. è¯­æ³•åˆ†æ
    - åˆ é™¤ä¸»æµæ•°åç§è¯­è¨€å­˜åœ¨è¯­æ³•è§£æé”™è¯¯æˆ–è€…è¯­æ³•é”™è¯¯çš„ä»£ç 
7. é™æ€åˆ†æ
    - ç»“åˆé™æ€åˆ†æå·¥å…·ï¼Œæ‰«æå¹¶å®šä½å½±å“ä»£ç å¯é æ€§å’Œå¯ç»´æŠ¤æ€§çš„161ç§Bugï¼Œå½±å“ä»£ç å®‰å…¨æ€§çš„197ç§æ¼æ´

```python
# "__init__" method should not return a value

# Noncompliant: a TypeError will be raised
class MyClass(object):
    def __init__(self):
        self.message = 'HelloWorld'
        return self  

# Compliant solution
class MyClass(object):
    def __init__(self):
        self.message = 'HelloWorld'
```

ä¸Šè¿°ä»£ç å±•ç¤ºäº†pythonä¸­çš„ä¸€ç§bugæ¨¡å¼ï¼Œå³ __init__  æ–¹æ³•ä¸åº”è¯¥è¿”å›å€¼ã€‚

## è®­ç»ƒ

### è®­ç»ƒè¶…å‚æ•°

åˆ†è¯å™¨:
- åŸºäºå­—èŠ‚ç çš„ BPE åˆ†è¯å™¨
- è¯è¡¨å¤§å°ï¼š49,152

æ¨¡å‹ç»“æ„:
- RoPE (Rotary Positional Embedding) ç›¸å¯¹ä½ç½®ç¼–ç 
- ä¸­é—´å…¨è¿æ¥å±‚é‡‡ç”¨ SwiGLU
- Grouped Query Attention

è®­ç»ƒé…ç½®:
- 70% ä¸ºç»“æ„åŒ– FIM (Fill in the middle)è®­ç»ƒä»»åŠ¡ï¼Œ30% ä¸ºè‡ªå›å½’è¯­è¨€æ¨¡å‹ä»»åŠ¡ï¼›
- BFloat 16 æ•°æ®ç±»å‹
- AdamW ä¼˜åŒ–å™¨ï¼Œå­¦ä¹ ç‡æœ€å¤§1e-5ï¼Œæœ€å° 1e-6ï¼Œé‡‡ç”¨ä½™å¼¦è¡°å‡
- é¢„è®­ç»ƒé•¿åº¦ä¸º 32,768


## å®éªŒç»“æœ

### NL2Code åŸºå‡†æµ‹è¯•

è¡¨1 å±•ç¤ºäº† aiXcoder-7B Base æ¨¡å‹åœ¨ç‹¬ç«‹æ–¹æ³•ç”ŸæˆåŸºå‡†ä¸Šçš„è¡¨ç°ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨å„å¤§é¢„è®­ç»ƒåŸºç¡€æ¨¡å‹ä¸­è¡¨ç°å¾ˆå¥½ï¼Œåœ¨ç™¾äº¿çº§å‚æ•°é‡ä¸‹æ‹¥æœ‰å½“å‰æœ€å¥½çš„æ•ˆæœã€‚

![table_1](./assets/table_1.png)


### ä»£ç è¡¥å…¨ (Fill in the Middle)

ä¸ Table 1 çš„ Stand alone nl2code ä¸åŒï¼Œåœ¨å®é™…ç¼–ç¨‹åœºæ™¯ä¸­ï¼Œæˆ‘ä»¬æ›´éœ€è¦è€ƒè™‘å…‰æ ‡ä¸Šä¸‹æ–‡çš„ä»£ç è¡¥å…¨èƒ½åŠ›ã€‚ä¸€èˆ¬è€Œè¨€ï¼Œå„ç§å¼€æºä»£ç å¤§æ¨¡å‹éƒ½ä¼šè€ƒè™‘åœ¨é¢„è®­ç»ƒä¸­åŠ å…¥Fill in the middle(FIM) æ¨¡å¼ï¼Œæ¥å¼ºåŒ–æ¨¡å‹åœ¨è€ƒè™‘ä»£ç ä¸Šä¸‹æ–‡çš„åœºæ™¯ä¸‹ç”Ÿæˆæ›´å‡†ç¡®çš„ç»“æœã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†ä»¥FIMä¸ºé»˜è®¤ä»£ç è¡¥å…¨æ–¹å¼ï¼Œè¯„æµ‹å„ä¸ªæ¨¡å‹åœ¨å®é™…ç¼–ç¨‹åœºæ™¯ä¸­çš„èƒ½åŠ›ã€‚

å½“å‰è€ƒè™‘ä¸Šä¸‹æ–‡çš„ä»£ç è¡¥å…¨ï¼Œä¸»æµè¯„æµ‹é›†æ˜¯ Santacoder(Ben Allal et al., 2023) æå‡ºæ¥çš„å•è¡Œè¯„æµ‹æ–¹æ³•ã€‚è¯¥è¯„æµ‹é›†ä¼šä»HumanEval æˆ–è€… MultiPL-E ä¸­æŠ½å–çš„å•è¡Œä»£ç ï¼Œç„¶ååœ¨ç»™å®šå®Œæ•´çš„ä¸Šæ–‡ä¸ä¸‹æ–‡æ¡ä»¶ä¸‹ï¼Œè¯„ä¼°æ¨¡å‹ç”Ÿæˆç»“æœçš„Exact MatchæŒ‡æ ‡ã€‚

![table_2](./assets/table_2.png)


ä¸ºäº†è¿›ä¸€æ­¥ç²¾ç»†åœ°è¯„æµ‹ä»£ç å¤§æ¨¡å‹åœ¨ä»£ç è¡¥å…¨ä¸Šçš„èƒ½åŠ›ï¼ŒaiXcoder æ„å»ºäº†ä¸€ä¸ªæ•°æ®é‡æ›´å¤§ï¼Œè¢«æµ‹ä»£ç å¤šæ ·æ€§æ›´é«˜ã€è¢«æµ‹ä»£ç ä¸Šä¸‹æ–‡é•¿åº¦æ›´é•¿ã€æ›´æ¥è¿‘å®é™…å¼€å‘é¡¹ç›®çš„è¯„æµ‹é›†ï¼Œè¯¥è¯„æµ‹é›†ä¹Ÿå°†åŒæ­¥åœ¨GitHubä¸Šå¼€æºã€‚åœ¨è¯„ä¼°è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä¿è¯ä¸åŒä»£ç å¤§æ¨¡å‹ä¹‹é—´é‡‡ç”¨ç›¸åŒçš„16Kæœ€å¤§åºåˆ—é•¿åº¦ï¼Œå¹¶ä¸”è¯„ä¼°ä¸åŒåœºæ™¯ä¸‹çš„ç”Ÿæˆæ•ˆæœï¼Œä¾‹å¦‚ç”Ÿæˆå®Œæ•´æ–¹æ³•å—ã€æ¡ä»¶åˆ¤æ–­å—ã€å¾ªç¯å¤„ç†å—ã€å¼‚å¸¸æ•æ‰å—ç­‰åä¸‰ç§æƒ…å†µã€‚

Table 3 å±•ç¤ºäº†ä¸åŒæ¨¡å‹åœ¨ä¸åŒè¯­è¨€ä¸Šçš„å¹³å‡ç”Ÿæˆæ•ˆæœï¼Œæœ€ç»ˆçš„è¯„ä¼°ç»“æœæ˜¯æ‰€æœ‰è¡¥å…¨åœºæ™¯ä¸è¯„æµ‹æ ·æœ¬çš„å‡å€¼ã€‚aiXcoder 7B Base æ¨¡å‹åœ¨å„å¤§ç¼–ç¨‹è¯­è¨€ï¼Œå„ç§è¯„ä¼°æ ‡å‡†ä¸‹éƒ½æ˜¯æ•ˆæœæœ€å¥½çš„ï¼Œè¿™è¡¨æ˜aiXcoder 7B Base åœ¨æœ€åŸºç¡€çš„ä»£ç è¡¥å…¨èƒ½åŠ›ä¸Šæ˜¯æ‰€æœ‰åŒé‡çº§å¼€æºæ¨¡å‹æœ€å¥½çš„ï¼Œæœ€é€‚åˆç”¨äºå®é™…ç¼–ç¨‹åœºæ™¯ä¸­æä¾›ä»£ç è¡¥å…¨èƒ½åŠ›çš„åŸºç¡€æ¨¡å‹ã€‚

![table_3](./assets/table_3.png)

å¯¹äº Table 3 ä¸­æ¯ä¸€æ¡è¯„æµ‹ç»“æœï¼Œå…¶éƒ½æœ‰æ›´ä¸ºè¯¦ç»†çš„è¯„æµ‹ç»´åº¦ã€‚Table 4 åˆ° 7  å±•ç¤ºäº†ä¸åŒæ¨¡å‹åœ¨ä¸åŒè¯­è¨€ä¸Šå¤šç»´åº¦è¯„ä¼°çš„ç»†èŠ‚ï¼š

- **Method signature**: è¡¨ç¤ºæ¨¡å‹æ ¹æ®ä¸Šä¸‹æ–‡ç”Ÿæˆæ–¹æ³•ç­¾åï¼›
- **Method body**: è¡¨ç¤ºæ¨¡å‹æ ¹æ®ä¸Šä¸‹æ–‡ï¼ŒåŒ…æ‹¬å‡½æ•°ç­¾åï¼Œç”Ÿæˆå®Œæ•´çš„æ–¹æ³•ä½“ï¼›
- **Single line**: è¡¨ç¤ºå•è¡Œä»£ç è¡¥å…¨ï¼›
- **Method with comment**: è¡¨ç¤ºæ ¹æ®ä¸Šä¸‹æ–‡ï¼ŒåŒ…æ‹¬å‡½æ•°ç­¾åä¸å‡½æ•°æ³¨é‡Šï¼Œç”Ÿæˆå¯¹åº”çš„å‡½æ•°ä½“ï¼›
- **Empty**: è¡¨ç¤ºåœ¨ä¸Šä¸‹æ–‡å®Œæ•´çš„æƒ…å†µä¸‹ï¼Œæ¨¡å‹éœ€è¦é¢„æµ‹ä¸ºç©ºï¼›
- **Method body top, mid, bottom**: è¡¨ç¤ºåˆ†åˆ«åœ¨å‡½æ•°ä½“ä¸ŠåŠéƒ¨åˆ†ï¼Œå‡½æ•°ä½“ä¸­é—´éƒ¨åˆ†ï¼Œå‡½æ•°ä½“ä¸‹åŠéƒ¨åˆ†çš„ä»£ç ç”Ÿæˆæ•ˆæœï¼›
- **If, for, while, try, switch statement**: è¡¨ç¤ºç”Ÿæˆæ¡ä»¶ä»£ç å—ã€å¾ªç¯ä»£ç å—ã€å¼‚å¸¸æ•æ‰ä»£ç å—ã€æ¡ä»¶åˆ†æ”¯ä»£ç å—çš„æ•ˆæœ;

![table_4](./assets/table_4.png)

![table_5](./assets/table_5.png)

![table_6](./assets/table_6.png)

![table_7](./assets/table_7.png)


### è·¨æ–‡ä»¶ä»£ç ç”Ÿæˆ

ä»£ç å¤§æ¨¡å‹å¦ä¸€ä¸ªæ¯”è¾ƒé‡è¦çš„èƒ½åŠ›æ˜¯è·¨æ–‡ä»¶çš„ä»£ç ä¸Šä¸‹æ–‡ç†è§£èƒ½åŠ›ï¼Œå› ä¸ºå¼€å‘è€…åœ¨å®é™…ç¼–å†™é¡¹ç›®ä¸­ï¼Œç»å¸¸éœ€è¦è€ƒè™‘å½“å‰é¡¹ç›®å…¶å®ƒæ–‡ä»¶å†…çš„ä¿¡æ¯ã€‚å› æ­¤æˆ‘ä»¬é‡‡ç”¨äº†CrossCodeEval (Ding et al., 2023)è¯„æµ‹é›†ï¼Œæ¥è¯„ä¼°æ¨¡å‹æå–è·¨æ–‡ä»¶ä¸Šä¸‹æ–‡ä¿¡æ¯çš„èƒ½åŠ›ã€‚

åœ¨ Table 8 ä¸­ï¼Œé¦–å…ˆä½œä¸º Baselineï¼Œåœ¨å•æ–‡ä»¶çš„æƒ…å†µä¸‹è¯„æµ‹å„ä»£ç å¤§æ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›ã€‚ç„¶ååœ¨ BM25 ä¸ºç›¸ä¼¼æ€§æŒ‡æ ‡çš„æƒ…å†µä¸‹ï¼Œé€šè¿‡ä¸Šæ–‡æœç´¢é¡¹ç›®å†…ç›¸ä¼¼çš„ä»£ç å¹¶ä½œä¸ºpromptï¼Œå†æ¬¡è¯„ä¼°æ¨¡å‹çš„ç”Ÿæˆæ•ˆæœã€‚æœ€åï¼Œw/Ref. è¡¨ç¤ºå‡è®¾æˆ‘ä»¬çŸ¥é“æ­£ç¡®çš„References ä»£ç æ˜¯ä»€ä¹ˆæ ·çš„ï¼Œç„¶åé€šè¿‡ References æœç´¢é¡¹ç›®å†…ç›¸ä¼¼çš„ä»£ç ä½œä¸ºpromptï¼Œå†æ¬¡è¯„ä¼°æ¨¡å‹çš„ç”Ÿæˆæ•ˆæœã€‚æœ€ç»ˆ aiXcoder-7B æ¨¡å‹åœ¨æ‰€æœ‰è¯­è¨€ä¸Šçš„æ•ˆæœéƒ½æ˜¯å¾ˆå¥½çš„ï¼Œè¿™è¯æ˜äº†æˆ‘ä»¬æ¨¡å‹åœ¨æå–ä¸Šä¸‹æ–‡ä¿¡æ¯ä¸Šï¼Œå°¤å…¶æ˜¯è·¨æ–‡ä»¶çš„ä¸Šä¸‹æ–‡ä¿¡æ¯çš„èƒ½åŠ›ã€‚

![table_8](./assets/table_8.png)


## License


The source code in this repository is licensed under the [Apache-2.0](https://www.apache.org/licenses/LICENSE-2.0) License - see the LICENSE file for details. 
The model weights are licensed under the [Model License](./MODEL_LICENSE) for academic research use; for commercial use, please apply by sending an email to support@aixcoder.com.


## Acknowledgments

We would like to thank all contributors to the open-source projects and datasets that made this work possible.

For any questions or issues, please open an issue on this repository.

Thank you for your interest in our Code Large Language Model. We look forward to your contributions and feedback!